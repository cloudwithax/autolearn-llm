# FP8 GRPO Training Requirements
# Tested on RTX 40xx/50xx, H100, L4

# Core
unsloth>=2024.12
unsloth_zoo
vllm>=0.6.0
torch>=2.4.0

# FP8 Support (PyTorch nightly for CUDA 12.8)
# Install separately:
# pip install --pre torchao --index-url https://download.pytorch.org/whl/nightly/cu128 --force-reinstall
# pip install --pre fbgemm-gpu fbgemm-gpu-genai --index-url https://download.pytorch.org/whl/cu128 --force-reinstall

# RL Training
trl>=0.12.0
transformers>=4.46.0
datasets>=3.0.0
accelerate>=1.0.0
peft>=0.13.0
bitsandbytes>=0.43.0  # 4-bit quantization for legacy GPUs

# Utilities
numba
numpy>=1.26.0
pyyaml
wandb  # optional, for logging

# Code Quality (for code rewards)
ruff>=0.5.0         # Fast linter
mypy>=1.11.0        # Type checker (optional)
